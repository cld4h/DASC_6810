@article{Goutham2021,
Abstract = {The relationship between the wind speed derived from the outputs of a numerical-weather-prediction model and from observations is explored using statistical and machine-learning models. Eight years of wind-speed measurements at a height of 10 m (from 2010 to 2017) from 171 stations spread over mainland France and Corsica are used for reference. Operational analyses from the European Center for Medium Range Weather Forecasts (ECMWF) provide the model information not only on the surface flow, but on other aspects of the atmospheric state at the location (or above) each station. In a first step, a large number of explanatory variables are used as input to several models (linear regressions, k-nearest neighbours, random forests, and gradient boosting). The modelled wind speed in the ECMWF analyses, by itself, has root-mean-square errors over all stations distributed widely around a median of 1.42 m s - 1 . Using statistical post-processing and making use of a historical dataset for traini},
Author = {Goutham, Naveen and Alonzo, Bastien and Dupré, Aurore and Plougonven, Riwal and Doctors, Rebeca and Liao, Lishan and Mougeot, Mathilde and Fischer, Aurélie and Drobinski, Philippe},
ISSN = {00068314},
Journal = {Boundary-Layer Meteorology},
Keywords = {WIND speed, LONG-range weather forecasting, PREDICTION models, RANDOM forest algorithms, WIND shear, NUMERICAL weather forecasting, FRANCE, Downscaling, Machine learning, Surface wind speed},
Number = {1},
Pages = {133 - 161},
Title = {Using Machine-Learning Methods to Improve Surface Wind Speed from the Outputs of a Numerical Weather Prediction Model.},
Volume = {179},
URL = {https://link.springer.com/article/10.1007/s10546-020-00586-x},
Year = {2021},
}

@article{Hou2022,
title = {Improving the forecast accuracy of ECMWF 2-m air temperature using a historical dataset},
journal = {Atmospheric Research},
volume = {273},
pages = {106177},
year = {2022},
issn = {0169-8095},
doi = {https://doi.org/10.1016/j.atmosres.2022.106177},
url = {https://www.sciencedirect.com/science/article/pii/S0169809522001636},
author = {Zhaolu Hou and Jianping Li and Lei Wang and Yazhou Zhang and Ting Liu},
keywords = {Model forecast correction, Analog, Historical data, 2-m air temperature, Cold wave, Qinghai Tibet Plateau},
abstract = {The 2-m air temperature (T2m) is an important meteorological variable and has been the focus of meteorological forecasting. Although the numerical weather model is an important means of forecasting, it typically presents forecasting errors that cannot be eliminated by improving the ability of the numerical model to reproduce the processes. Thus, a statistical correction of the forecast results is required. In this study, we applied the local dynamical analog (LDA) method to correct the operational T2m forecast product obtained from the European Centre for Medium-Range Weather Forecasts with the lead time of 24–240 h. To our knowledge, for the first time, we used spatially adjacent grids from high-resolution grid data as potential analog pools to compensate for the short duration of historical data. The T2m of weather forecasts in East Asia for December 2018 was improved by LDA correction with a small sample condition. Compared with ERA5 and station observation data, the results show that the root mean square error can be reduced by 2\%–4\% and the correlation coefficient can be increased by 1\%–5\% for different lead times, with the most distinct improvement effect for the medium-term forecast time. The Qinghai Tibet Plateau, Mongolia Plateau, and other areas, where the raw prediction error is relatively high, presented better performance than other regions. For a cold-wave process, we also demonstrate that the corrected results based on analogs present better forecasting skill performance than raw forecast results. The analog correction with the LDA method, which combines statistical and model dynamical techniques, is proposed to be integrated with other advanced operational models. The forecast skill of T2m was improved by a historical dataset, which may contribute to energy management and the construction industry.}
}

@article {Zampieri2023,
      author = "Lorenzo Zampieri and Gabriele Arduini and Marika Holland and Sarah P. E. Keeley and Kristian Mogensen and Matthew D. Shupe and Steffen Tietsche",
      title = "A Machine Learning Correction Model of the Winter Clear-Sky Temperature Bias over the Arctic Sea Ice in Atmospheric Reanalyses",
      journal = "Monthly Weather Review",
      year = "2023",
      publisher = "American Meteorological Society",
      address = "Boston MA, USA",
      volume = "151",
      number = "6",
      doi = "10.1175/MWR-D-22-0130.1",
      pages=      "1443 - 1458",
      url = "https://journals.ametsoc.org/view/journals/mwre/151/6/MWR-D-22-0130.1.xml"
}

@book{ISL2,
author = {Gareth James and Daniela Witten and Trevor Hastie and Robert Tibshirani},
title = {An Introduction to Statistical Learning},
doi = {https://doi.org/10.1007/978-1-0716-1418-1},
url = {https://link.springer.com/book/10.1007/978-1-0716-1418-1},
year = {2021},
publisher = {Springer New York, NY}
}

@article{Tibshirani1996,
author = {Tibshirani, Robert},
title = {Regression Shrinkage and Selection Via the Lasso},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {58},
number = {1},
pages = {267-288},
keywords = {quadratic programming, regression, shrinkage, subset selection},
doi = {https://doi.org/10.1111/j.2517-6161.1996.tb02080.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1996.tb02080.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1996.tb02080.x},
abstract = {SUMMARY We propose a new method for estimation in linear models. The ‘lasso’ minimizes the residual sum of squares subject to the sum of the absolute value of the coefficients being less than a constant. Because of the nature of this constraint it tends to produce some coefficients that are exactly 0 and hence gives interpretable models. Our simulation studies suggest that the lasso enjoys some of the favourable properties of both subset selection and ridge regression. It produces interpretable models like subset selection and exhibits the stability of ridge regression. There is also an interesting relationship with recent work in adaptive function estimation by Donoho and Johnstone. The lasso idea is quite general and can be applied in a variety of statistical models: extensions to generalized regression models and tree-based models are briefly described.},
year = {1996}
}

